\begin{abstract}

Understanding how we are able to perform a diverse set of complex
tasks has been a central question for the Artificial Intelligence
community. Drawing parallels from the small-world phenomenon in social
networks, we hypothesise that the key to this ability lies in finding
a set of composable subtasks that ``easily'' span the set of all
tasks. We model our hypothesis using the options framework from
reinforcement learning, and prove that given well-distributed
subtasks, an agent can perform any task using only a logarithmic
combination of subtasks and primitive actions. We also present an
algorithm for an agent to learn these subtasks through a modest number
of explorations without knowledge of the underlying domain.
Experimental results show that these subtasks outperform other popular
subtask generation schemes on standard domains. \draft{What is our
contribution?}
% Relevance to lifelong learning?

\end{abstract}
