\begin{abstract}

Understanding how we are able to perform a diverse set of complex
tasks has been a central question for the Artificial Intelligence
community. We hypothesise that the key to this ability lies in finding
a set of composable subtasks that ``easily'' span the set of all
tasks. Drawing parallels from Kleinberg's work on the small-world
phenomenon in social networks \cite{Kleinberg}, we model our
hypothesis using the options framework from reinforcement learning
\cite{SuttonPrecupSingh1998}, and prove that given well-distributed
subtasks, an agent can perform any task using only a logarithmic
combination of subtasks and primitive actions. Experimental results
show that these subtasks outperform other popular subtask generation
schemes on standard domains.

\end{abstract}
